# -*- coding: utf-8 -*-
"""Churn_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/KunjanMinama/Customer-Churn-Prediction/blob/main/Churn_Prediction.ipynb

# **Customer Churn Prediction**

**1. Importing the Dependencies**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pickle
import joblib

"""**2. Data Loading And Understandings**"""

df=pd.read_csv('/content/telco.csv')

df.shape

df.describe()

df.info()

df.head()

pd.set_option('display.max_columns',None)

df.head(2)

#droping cutomerID column as this is not requires=d for medelling
df = df.drop(columns=['customerID'])

df.head(2)

# pi=rinting the Unique Values in all the Columns

numerical_features_list = ["tenure","MonthlyCharges","TotalCharges"]

for col in df.columns:
  if col not in numerical_features_list:
   print(col, df[col].unique())
   print("."*100)

#df[df["TotalCharges"]==" "]

len(df[df["TotalCharges"]==" "])

df["TotalCharges"] = df["TotalCharges"].replace({" ": "0.0"})

df["TotalCharges"] = df["TotalCharges"].astype(float)

df.info()

#checking the class distribution of target column
print(df["Churn"].value_counts())

"""# **Insights:**
1. Customer ID removed as it is not required for madelling
2. No missing in the dataset
3. Missing Values in the TotalCharges column were replaced with 0.
4. Class imbalance identified in the target.

**3. Exploratory Data Analysis (EDA)**
"""

df.shape

df.columns

df.head()

df.describe()

"""**Numerical Features - Analysis**

Understand the Distribution of the Numerical Features
"""

def plot_histogram(df, column_name):
  plt.figure(figsize=(10, 5))
  sns.histplot(df[column_name], kde=True)
  plt.title("Distribution of {column_name}")

  # calculate the mean and median for the column
  col_mean = df[column_name].mean()
  col_median = df[column_name].median()

  #add vertical line for mean and meadian
  plt.axvline(col_mean, color='red', linestyle='--', label="MEan")
  plt.axvline(col_median, color='green', linestyle='-', label="Meadian")
  plt.legend()

  plt.show()

plot_histogram(df, "tenure")

plot_histogram(df, column_name="MonthlyCharges")

plot_histogram(df, column_name="TotalCharges")

"""**Box Plot For numerical Features**"""

def boxplot(df, column_name):
  plt.figure(figsize=(5,3))
  sns.boxplot(y=df[column_name])
  plt.title(f"Box Plot for {column_name}")
  plt.ylabel(column_name)
  plt.show()

boxplot(df, column_name="tenure")

boxplot(df, column_name="MonthlyCharges")

boxplot(df, column_name="TotalCharges")

"""**Correlation Heatmap for numerical columns**"""

# correlation matrix - heatmap
plt.figure(figsize=(8,4))
sns.heatmap(df[["tenure","MonthlyCharges","TotalCharges"]].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

"""Categorical features - Analysis

"""

df.columns

df.info()

object_cols = df.select_dtypes(include="object").columns.to_list()

object_cols = ["SeniorCitizen"] + object_cols

for col in object_cols:
  plt.figure(figsize=(5, 3))
  sns.countplot(x=df[col])
  plt.title(f"Count Plot of {col}")
  plt.show()

"""# **4. Data Preprocessing**"""

df.head(3)

"""**Label Encoding of target Column**"""

df["Churn"] = df["Churn"].replace({"Yes": 1, "No": 0})

df.head(3)

print(df["Churn"].value_counts())

"""**Label encoding of categorical columns**"""

#Identifying columns with object data type

object_columns = df.select_dtypes(include="object").columns

print(object_columns)

# initialize a dictionary to save the encoders

encoders = {}

# apply label encoding and store the encoders

for column in object_columns:
  label_encoder = LabelEncoder()
  df[column] = label_encoder.fit_transform(df[column])
  encoders[column] = label_encoder

  # save the encoders to a pickle file
  with open("encoders.pkl", "wb") as f:
    pickle.dump(encoders, f)

encoders

df.head(3)

"""**Training and test data slpit**"""

#Spliting the features and target
X = df.drop(columns=["Churn"])
y = df["Churn"]

#SPlit training and test data

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(y_train.shape)

print(y_train.value_counts())

"""Synthetic Minority Oversampling Technique (SMOTE)"""

smote = SMOTE(random_state=42)

X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

print(y_train_smote.value_counts())

"""**5. Model Training**

Training With Default hyperparameters
"""

# dictionary of models
models={
    "Deciion Tree" : DecisionTreeClassifier(random_state=42),
    "Random Forest" : RandomForestClassifier(random_state=42),
    "XGBoost" : XGBClassifier(random_state=42)

}

# dictionary to score the cross validation results
cv_results = {}

# perform 5 folds cross validation for each model
for model_name, model in models.items():
  print(f"Training {model_name} with default parameters")
  scores = cross_val_score(model, X_train_smote, y_train_smote, cv=5, scoring = "accuracy")
  cv_results[model_name] = scores
  print(f"{model_name} cross_validation accuracy : {np.mean(scores):.2f}")
  print("-"*70)

cv_results

"""Random Forest Gives the highest accuracy compared to other models with default parameters"""

rfc = RandomForestClassifier(random_state=42)
rfc.fit(X_train_smote, y_train_smote)

model.fit(X_train_smote, y_train_smote)

"""**6. Model Evaluatioin**"""

# evaluate on test data

y_test_pred = model.predict(X_test)

print(accuracy_score(y_test, y_test_pred))
print(confusion_matrix(y_test, y_test_pred))
print(classification_report(y_test, y_test_pred))

X.columns.tolist()

import pickle
# save the trained model as a pickle file
model_data_to_save = {"model": rfc,"features_names": X.columns.tolist()}
with open("customer_churn_model.pkl", "wb") as f:
  pickle.dump(model_data_to_save, f)

"""**7. Load the saved model and build a Predictive System**"""

# load the saved model and the features names

with open("customer_churn_model.pkl", "rb") as f:
 model_data = pickle.load(f)

loaded_model = model_data["model"]
feature_names = model_data["features_names"]

print(loaded_model)

print(feature_names)

input_data_dict = {
    'gender': 'Female',
    'SeniorCitizen': '0',
    'Partner': 'Yes',
    'Dependents': 'No',
    'tenure': '1',
    'PhoneService': 'No',
    'MultipleLines': 'No phone service',
    'InternetService': 'DSL',
    'OnlineSecurity': 'No',
    'OnlineBackup': 'Yes',
    'DeviceProtection': 'No',
    'TechSupport': 'No',
    'StreamingTV': 'No',
    'StreamingMovies': 'No',
    'Contract': 'Month-to-month',
    'PaperlessBilling': 'Yes',
    'PaymentMethod': 'Electronic check',
    'MonthlyCharges': 29.85,
    'TotalCharges': 29.85


}

input_data_df = pd.DataFrame([input_data_dict])

with open("encoders.pkl", "rb") as f:
  encoders = pickle.load(f)



#encode categorical features using the saved encoders

for column, encoder in encoders.items():
  input_data_df[column] = encoder.transform(input_data_df[column])

# Make a prediction
prediction = loaded_model.predict(input_data_df)
pred_prob = loaded_model.predict_proba(input_data_df)

print(prediction)

# results

print(f"prediction: {'Churn' if prediction[0] == 1 else 'No Churn'}")
print(f"Prediction Probability: {pred_prob}")

print(input_data_df.head())

input_data_df.head()

encoders

"""**To do:**
1. Implement Hyperparameter Tuining
2. Try Model Selection
3. try Downsampling
4. try to address the overfitting
5. try startified k fold CV
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import numpy as np
# import pandas as pd
# import pickle
# import joblib
# 
# st.set_page_config(page_title="Customer Churn Prediction", layout="wide")
# 
# # ---------------------------
# # Load Model & Encoders
# # ---------------------------
# with open("customer_churn_model.pkl", "rb") as f:
#     model_data = pickle.load(f)
# 
# model = model_data["model"]
# feature_names = model_data["features_names"]
# 
# with open("encoders.pkl", "rb") as f:
#     encoders = pickle.load(f)
# 
# st.title("üìä Customer Churn Prediction App")
# st.write("Fill the customer details to predict if the customer will churn.")
# 
# # ---------------------------
# # Input UI
# # ---------------------------
# col1, col2, col3 = st.columns(3)
# 
# with col1:
#     gender = st.selectbox("Gender", ["Male", "Female"])
#     senior_citizen = st.selectbox("Senior Citizen", ["No", "Yes"])
#     partner = st.selectbox("Partner", ["Yes", "No"])
#     dependents = st.selectbox("Dependents", ["Yes", "No"])
#     phone_service = st.selectbox("Phone Service", ["Yes", "No"])
#     multiple_lines = st.selectbox("Multiple Lines", ["No phone service", "No", "Yes"])
#     tenure = st.number_input("Tenure (months)", 0, 72)
# 
# with col2:
#     internet_service = st.selectbox("Internet Service", ["DSL", "Fiber optic", "No"])
#     online_security = st.selectbox("Online Security", ["Yes", "No", "No internet service"])
#     online_backup = st.selectbox("Online Backup", ["Yes", "No", "No internet service"])
#     device_protection = st.selectbox("Device Protection", ["Yes", "No", "No internet service"])
#     tech_support = st.selectbox("Tech Support", ["Yes", "No", "No internet service"])
#     streaming_tv = st.selectbox("Streaming TV", ["Yes", "No", "No internet service"])
#     streaming_movies = st.selectbox("Streaming Movies", ["Yes", "No", "No internet service"])
# 
# with col3:
#     contract = st.selectbox("Contract", ["Month-to-month", "One year", "Two year"])
#     paperless_billing = st.selectbox("Paperless Billing", ["Yes", "No"])
#     payment_method = st.selectbox("Payment Method",
#                              ["Electronic check", "Mailed check", "Bank transfer (automatic)", "Credit card (automatic)"])
#     monthly_charges = st.number_input("Monthly Charges", 0.0, 200.0)
#     total_charges = st.number_input("Total Charges", 0.0, 10000.0)
# 
# # ---------------------------
# # Prepare Input Data
# # ---------------------------
# input_dict = {
#     "gender": gender,
#     "SeniorCitizen": senior_citizen,
#     "Partner": partner,
#     "Dependents": dependents,
#     "tenure": tenure,
#     "PhoneService": phone_service,
#     "MultipleLines": multiple_lines,
#     "InternetService": internet_service,
#     "OnlineSecurity": online_security,
#     "OnlineBackup": online_backup,
#     "DeviceProtection": device_protection,
#     "TechSupport": tech_support,
#     "StreamingTV": streaming_tv,
#     "StreamingMovies": streaming_movies,
#     "Contract": contract,
#     "PaperlessBilling": paperless_billing,
#     "PaymentMethod": payment_method,
#     "MonthlyCharges": monthly_charges,
#     "TotalCharges": total_charges,
# }
# 
# df_input = pd.DataFrame([input_dict])
# 
# # Process SeniorCitizen separately (not in loaded_encoders)
# df_input['SeniorCitizen'] = df_input['SeniorCitizen'].apply(lambda x: 1 if x == 'Yes' else 0)
# 
# # Apply saved LabelEncoders
# for col, encoder in encoders.items():
#     if col in df_input.columns:
#         df_input[col] = encoder.transform(df_input[col].astype(str))
# 
# # ---------------------------
# # Prediction
# # ---------------------------
# if st.button("üîç Predict Churn"):
#     pred = model.predict(df_input)[0]
#     pred_prob = model.predict_proba(df_input)[0][1]
# 
#     if pred == 1:
#         st.error(f"‚ö†Ô∏è Customer is likely to CHURN ‚Äî Probability: {pred_prob:.2f}")
#     else:
#         st.success(f"‚úÖ Customer will NOT churn ‚Äî Probability: {1-pred_prob:.2f}")
# 
#     st.write("### Encoded Input Data")
#     st.dataframe(df_input)

